{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11eb2e7",
   "metadata": {},
   "source": [
    "# Function Calling\n",
    "The recent fine tuning of the openai has added the additional arguments call functions by which the users can pass descriptions of the functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b654da34",
   "metadata": {},
   "source": [
    "# SetUp the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99729ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import openai \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pathlib import Path\n",
    "load_dotenv(Path(\"raj.env\"))\n",
    "openai.api_key=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6fdfc1",
   "metadata": {},
   "source": [
    "# Write the Api Call Function\n",
    "\n",
    "This is an external function that can be used to generate better result for the case gpt model does not have access to  the information.\n",
    "\n",
    " Example dummy function hard coded to return the same weather\n",
    "In production, this could be your backend API or an external API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "778984d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a13d2e5",
   "metadata": {},
   "source": [
    "A list of function definition can be passed to the openai. A better look at the list:\n",
    "\n",
    "\n",
    "{ name : name of the function \n",
    "  description: description of the function\n",
    "  parameters: it is an object \n",
    "       type = object\n",
    "       properties= \n",
    "           location : \n",
    "               type:\n",
    "               description:\n",
    "           unit:\n",
    "               type:\n",
    "               enum\n",
    "    required:\n",
    "    \n",
    " The 2 desriptions are importatnt as they are getting passed to the language model and then the model decide whether to use the function  (name) or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c43691",
   "metadata": {},
   "source": [
    "# Define the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab513e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5377b2f",
   "metadata": {},
   "source": [
    "# Call OpenAi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4361d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U openai\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b67355",
   "metadata": {},
   "source": [
    "# Call with Functions\n",
    "\n",
    "\n",
    "Here make the function call but notice that the output content is None but it returns the fnction call arguments which can be later used to call the get_weather function to get the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c139d137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8oFMoiWwO0AuU7OWaiU3VljjKxf6Y', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"location\": \"Boston, MA\"\\n}', name='get_current_weather'), tool_calls=None))], created=1706986162, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=18, prompt_tokens=92, total_tokens=110))\n",
      "The conent of the message is :\n",
      "None\n",
      "the function call is:\n",
      "FunctionCall(arguments='{\\n  \"location\": \"Boston, MA\"\\n}', name='get_current_weather')\n"
     ]
    }
   ],
   "source": [
    "## This is a list of message to pass to the language model.\n",
    "## Notice the first line of the message it is to ensure that response to the model is in JSON format.\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston?\"\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions\n",
    ")\n",
    "\n",
    "print(response)\n",
    "print(\"The conent of the message is :\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"the function call is:\")\n",
    "print(response.choices[0].message.function_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98858182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": {\"location\": \"Boston, MA\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args=json.loads(response.choices[0].message.function_call.arguments)\n",
    "get_current_weather(args)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e98891a",
   "metadata": {},
   "source": [
    "  Notice in the above response :  \n",
    ": function_call=   FunctionCall(arguments='{\\n  \"location\": \"Boston, MA\"\\n}', name='get_current_weather') \"\n",
    "\n",
    "Notice that the content is None.\n",
    "\n",
    "In the function_call the argument is \n",
    "                               args= { \" locations\" : \"Boston, MA\"} and \n",
    "        name of the function  \"name\" : 'get_current_weather'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8d3dca",
   "metadata": {},
   "source": [
    "# Function call with content ( no weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eea15b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8oFMprNyaKNSX1cFvghSFbXBCmosf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1706986163, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=86, total_tokens=96))\n",
      "The conent of the message is :\n",
      "Hello! How can I assist you today?\n",
      "the function call is:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## This has notihing to the above function\n",
    "messages = [\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    ")\n",
    "print(response)\n",
    "print(\"The conent of the message is :\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"the function call is:\")\n",
    "print(response.choices[0].message.function_call)\n",
    "## Check the function call which is None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98cb0d",
   "metadata": {},
   "source": [
    "# Function call auto (let openai choose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f16e274c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8oFMpl8bTgnbU4TooUIdiuCEOgsjK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1706986163, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=10, prompt_tokens=86, total_tokens=96))\n",
      "The conent of the message is :\n",
      "Hello! How can I assist you today?\n",
      "the function call is:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## We are using auto as the call.\n",
    "## As the message has nothing to do with the weather it is responding as usual\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "print(response)\n",
    "print(\"The conent of the message is :\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"the function call is:\")\n",
    "print(response.choices[0].message.function_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc8179f",
   "metadata": {},
   "source": [
    "# Function call is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "823b4f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8oFMqYPuW9RXG6alGTd5tHieJz4eO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1706986164, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=91, total_tokens=100))\n",
      "The conent of the message is :\n",
      "Hello! How can I assist you today?\n",
      "the function call is:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## Here the function call is None. So No function is being called.\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!. Answer in JSON format\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"none\"\n",
    ")\n",
    "print(response)\n",
    "print(\"The conent of the message is :\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"the function call is:\")\n",
    "print(response.choices[0].message.function_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a925b317",
   "metadata": {},
   "source": [
    "# Function call with get_current_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b2e454c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8oFMrus4kCXtzxEbEy7rWPsbv8q2z', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=FunctionCall(arguments='{\\n  \"location\": \"Boston, MA\"\\n}', name='get_current_weather'), tool_calls=None))], created=1706986165, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=99, total_tokens=110))\n",
      "The conent of the message is :\n",
      "None\n",
      "the function call is:\n",
      "FunctionCall(arguments='{\\n  \"location\": \"Boston, MA\"\\n}', name='get_current_weather')\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston!\",\n",
    "    }\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "print(response)\n",
    "print(\"The conent of the message is :\")\n",
    "print(response.choices[0].message.content)\n",
    "print(\"the function call is:\")\n",
    "print(response.choices[0].message.function_call)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c8b69",
   "metadata": {},
   "source": [
    "# Append the call and call function with args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f659b223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a helpful assistant designed to output JSON.'}, {'role': 'user', 'content': \"What's the weather like in Boston!\"}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'get_current_weather', 'arguments': '{\\n  \"location\": \"Boston, MA\"\\n}'}}]\n",
      "ChatCompletion(id='chatcmpl-8oFMrrUk6fqiibvZApvHAHcxvlbER', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The current weather in Boston, MA is 72 degrees Fahrenheit. It is sunny and windy.', role='assistant', function_call=None, tool_calls=None))], created=1706986165, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=19, prompt_tokens=91, total_tokens=110))\n",
      "The current weather in Boston, MA is 72 degrees Fahrenheit. It is sunny and windy.\n"
     ]
    }
   ],
   "source": [
    "message_dict={\n",
    "    \"role\": response.choices[0].message.role,\n",
    "    \"content\" : response.choices[0].message.content,\n",
    "    \"function_call\" : {\n",
    "       \"name\": response.choices[0].message.function_call.name,\n",
    "        \"arguments\" : response.choices[0].message.function_call.arguments\n",
    "    }\n",
    "}\n",
    "\n",
    "message_dict_json= json.dumps(message_dict)\n",
    "messages.append(json.loads(message_dict_json))\n",
    "\n",
    "args = json.loads(response.choices[0].message.function_call.arguments)\n",
    "observation = get_current_weather(args)\n",
    "\n",
    "print(messages)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation,\n",
    "        }\n",
    ")\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(response)\n",
    "\n",
    "print( response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec71191",
   "metadata": {},
   "source": [
    "# Notes: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287a54d9",
   "metadata": {},
   "source": [
    "The idea is to use different api or function to incorporate in the api call. Some simple rule to follow: \n",
    "1. Create an api get_current_weather.\n",
    "2. Write a function for function call ( as described above)\n",
    "3. Call openai with message acrording to the api and use functions= functions and function_call = {} and save response. \n",
    "4. Use the response to parse \n",
    "            {role:\n",
    "             content:\n",
    "             argumnets:\n",
    "             }\n",
    "   and append it calling message \n",
    "   messages = [\n",
    "    {\"role\": \"system\", \n",
    "     \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston!\",\n",
    "    }\n",
    "]\n",
    "\n",
    "It converted to \n",
    "[{'role': 'system',\n",
    "  'content': 'You are a helpful assistant designed to output JSON.'},\n",
    " {'role': 'user', 'content': \"What's the weather like in Boston!\"},\n",
    " {'role': 'assistant',\n",
    "  'content': None,\n",
    "  'function_call': {'name': 'get_current_weather',\n",
    "   'arguments': '{\\n  \"location\": \"Boston, MA\"\\n}'}}\n",
    "   ]\n",
    "\n",
    "5. Next call the function get_current_weather and append it to the message: \n",
    "args = json.loads(response.choices[0].message.function_call.arguments)\n",
    "observation = get_current_weather(args)\n",
    "\n",
    "messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation,\n",
    "        }\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    ")\n",
    "\n",
    "print( response.choices[0].message.content)\n",
    "\n",
    "The current weather in Boston, MA is 72 degrees Fahrenheit with a sunny and windy forecast.\n",
    "\n",
    "\n",
    "\n",
    "As we are using function and function call in the message the number of tokens increases. So we need to account for that in our call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf64619",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ea642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
